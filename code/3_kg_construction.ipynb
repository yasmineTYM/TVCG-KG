{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca312e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '/Users/yameitu/Documents/Yamei/Research/2024PVIS/python_code/')\n",
    "import utils\n",
    "from rdflib import URIRef\n",
    "from rdflib import Graph, URIRef, Literal, BNode, Namespace\n",
    "from rdflib.namespace import FOAF, RDF\n",
    "from rdflib.namespace import XSD\n",
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx \n",
    "# !pip install pydotplus\n",
    "# !pip install graphviz\n",
    "import io\n",
    "from IPython.display import display, Image\n",
    "from rdflib.tools.rdf2dot import rdf2dot\n",
    "import math \n",
    "import json\n",
    "import pydotplus\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdcb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOI_prefix = 'https://doi.org/'\n",
    "temp = pd.read_csv('../kg_data/0_affiliation2name_v3.csv')\n",
    "AFF_Mapping = dict(zip(temp['raw_affiliation'].tolist(), temp['wikidata'].tolist()))\n",
    "mapping = utils.loadjson('../kg_data/1_phrase2dbpedia_cleaned.json')\n",
    "mapping_keyword  = utils.loadjson('../kg_data/1_keyword2dbpedia_cleaned.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5dd0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "TVCG_P = Namespace('http://tvcg.org/property/')\n",
    "TVCG_C = Namespace('http://tvcg.org/class/')\n",
    "PRISM = Namespace(\"http://prismstandard.org/namespaces/basic/2.0/\")\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "MAG = Namespace(\"https://makg.org/property/\")\n",
    "MAGC = Namespace(\"https://makg.org/class/\")\n",
    "DATACITE = Namespace(\"http://purl.org/spar/datacite\")\n",
    "FABIO = Namespace(\"http://purl.org/spar/fabio/\")\n",
    "VISSURVEY = Namespace(\"http://vissurvey.org/property/\")\n",
    "ORG = Namespace('http://www.w3.org/ns/org#')\n",
    "CITO = Namespace(\"http://purl.org/spar/cito/\")\n",
    "RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "DBO = Namespace(\"http://dbpedia.org/ontology/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2519e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_rel = {\n",
    "    ('task', 'application'): \"applied_in\",\n",
    "    ('name', 'technique'): \"uses\",\n",
    "    ('task', 'name'): 'solved_by',\n",
    "    ('name', 'input_data'): 'feeds_in',\n",
    "    ('name', 'output_data'): 'generates',\n",
    "    ('name', 'evaluation_data'):'evaluated_on',\n",
    "    ('name', 'evaluation_technique'):'evaluated_by',\n",
    "    ('name', 'evaluation_baseline'):'evaluated_with'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d142d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_rel = {\n",
    "    'task': 'has_task',\n",
    "    'application': 'has_background',\n",
    "    'name': 'has_method',\n",
    "    'technique': 'has_technique',\n",
    "    'evaluation_data': 'has_evaluation_data',\n",
    "    'evaluation_technique': 'has_evaluation_technique',\n",
    "    'evaluation_baseline': 'has_evaluation_baseline',\n",
    "    'input_data': 'has_input_data',\n",
    "    'output_data': 'has_output_data',\n",
    "    'source_data': 'has_code'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc69905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(g):\n",
    "    stream = io.StringIO()\n",
    "    rdf2dot(g, stream, opts = {display})\n",
    "    dg = pydotplus.graph_from_dot_data(stream.getvalue())\n",
    "    png = dg.create_png()\n",
    "    display(Image(png))\n",
    "def mapKeyword2DB(keyword):\n",
    "    global mapping_keyword\n",
    "    if len(mapping_keyword[keyword])==0:\n",
    "        return None\n",
    "    else:\n",
    "        return mapping_keyword[keyword]\n",
    "def mapPhrase2DB(phrase):\n",
    "    global mapping \n",
    "    if len(mapping[phrase])==0:\n",
    "        return None\n",
    "    else:\n",
    "        return mapping[phrase]\n",
    "def findPairs(ele, total, prefix=None):\n",
    "    if isinstance(ele, dict):\n",
    "        for key, val in ele.items():\n",
    "            if isinstance(val, str) or (isinstance(val, list) and len(val)>0 and isinstance(val[0], str)):\n",
    "                if prefix:\n",
    "                    total[prefix+'_'+key] = val\n",
    "            else:\n",
    "                findPairs(val, total, key)\n",
    "    elif isinstance(ele, list) and len(ele)>0 and isinstance(ele[0], dict):\n",
    "        for one_dict in ele:\n",
    "            findPairs(one_dict, total, prefix)\n",
    "    return total\n",
    "def addSemantics(g, one_paper, paper_node):\n",
    "#     total = findPairs(one_paper['llm'], {})\n",
    "    total = one_paper['llm']['scientific_concepts']\n",
    "    ## add inter rel between ent and paper \n",
    "    for ele in total:\n",
    "        if ele in inter_rel:\n",
    "            rel_name = inter_rel[ele]\n",
    "            \n",
    "            if isinstance(total[ele], str):\n",
    "                g = addInterEnt(g, total[ele], paper_node, rel_name, ele)\n",
    "            elif isinstance(total[ele], list):\n",
    "                for e in total[ele]:\n",
    "                    g = addInterEnt(g, e, paper_node, rel_name, ele)\n",
    "    \n",
    "    ## add intra rel between ent\n",
    "#     for key, val in intra_rel.items():\n",
    "#         if key[0] in total and key[1] in total: ## exists both entities \n",
    "#             s = total[key[0]]\n",
    "#             t = total[key[1]]\n",
    "#             if isinstance(s, str) and isinstance(t, str):\n",
    "#                 addIntraEnt(g,s, t, key[0], key[1], val)\n",
    "#             elif isinstance(s, list) and isinstance(t, list):\n",
    "#                 for s_ in s:\n",
    "#                     for t_ in t:\n",
    "#                         addIntraEnt(g,s_, t_, key[0], key[1], val)\n",
    "#             elif isinstance(s, str) and isinstance(t, list):\n",
    "#                 for t_ in t:\n",
    "#                     addIntraEnt(g,s, t_, key[0], key[1], val)\n",
    "#             elif isinstance(s, list) and isinstance(t, str):\n",
    "#                 for s_ in s:\n",
    "#                     addIntraEnt(g,s_, t, key[0], key[1], val)\n",
    "    return g\n",
    "def searchKG(g, keyword, RDF_type_string):\n",
    "    sparql_ = f\"\"\"\n",
    "        SELECT *\n",
    "        where {{\n",
    "            ?target rdf:type  {RDF_type_string} .\n",
    "            ?target foaf:name \"{keyword}\"^^xsd:string .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = g.query(sparql_)\n",
    "        return list(output)\n",
    "    except:\n",
    "        print('ERROR searchKG:',keyword)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6e3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addInterEnt(g, ele, paper_node, rel_name, entType):\n",
    "    ent_node = searchKG(g, ele, \"<http://tvcg.org/class/\"+entType+\">\")\n",
    "    if len(ent_node) ==0:\n",
    "        ent_node = BNode()\n",
    "        g.add((ent_node, RDF.type, URIRef(\"http://tvcg.org/class/\"+entType)))\n",
    "        g.add((ent_node, FOAF.name, Literal(ele, datatype=XSD.string)))\n",
    "    else:\n",
    "        ent_node = ent_node[0][0]\n",
    "    g.add((paper_node, URIRef(\"http://tvcg.org/property/\"+rel_name), ent_node))\n",
    "    db = mapPhrase2DB(ele)\n",
    "    if db!=None:\n",
    "        for d in db:\n",
    "            g.add((ent_node, TVCG_P.seeAlso, URIRef(\"https://dbpedia.org/page/\"+d)))\n",
    "            g.add((URIRef(\"https://dbpedia.org/page/\"+d), FOAF.name, Literal(d, datatype=XSD.string)))\n",
    "            g.add((URIRef(\"https://dbpedia.org/page/\"+d), RDF.type, URIRef(\"https://tvcg.org/class/DBPedia\")))\n",
    "    return g \n",
    "\n",
    "def addIntraEnt(g, s, t, s_type, t_type, rel):\n",
    "    s_node = searchKG(g, s, \"<http://tvcg.org/class/\"+s_type+\">\")[0][0]\n",
    "    t_node = searchKG(g, t, \"<http://tvcg.org/class/\"+t_type+\">\")[0][0]\n",
    "    g.add((s_node, URIRef(\"http://tvcg.org/property/\"+rel), t_node))\n",
    "    return g \n",
    "def flatDataDict(ele, output):\n",
    "    if isinstance(ele, dict):\n",
    "        for key, val in ele.items():\n",
    "            if isinstance(val, str) or (isinstance(val, list) and len(val)>0 and isinstance(val[0], str)):\n",
    "                output[key] = val\n",
    "            else:\n",
    "                flatDataDict(val, output)\n",
    "    return output\n",
    "def addAuthorEntity(g, paper_node, row):\n",
    "    \n",
    "    authors = row['data']['article']['authors']\n",
    "\n",
    "    # print(authors)\n",
    "    for author in authors:\n",
    "        name = author['fullName']\n",
    "        if name!=None:\n",
    "            search_author = searchKG(g, name, '<https://makg.org/class/Author>')\n",
    "            if len(search_author)==0:\n",
    "                c = BNode()\n",
    "                g.add((c, RDF.type, MAGC.Author))\n",
    "                g.add((c, FOAF.name, Literal(name, datatype=XSD.string)))\n",
    "                aff = author['affiliation']\n",
    "                if aff!=None:\n",
    "                    url = AFF_Mapping[aff]\n",
    "                    if url == None or isinstance(url, str)==False or url==\"\":\n",
    "                        a = BNode()\n",
    "                        g.add((a, RDF.type, MAGC.Affiliation))\n",
    "                        g.add((a, FOAF.name, Literal(aff, datatype=XSD.string)))\n",
    "                    else:\n",
    "                        a = URIRef(url)\n",
    "                        g.add((a, FOAF.name, Literal(aff, datatype=XSD.string)))\n",
    "                        g.add((a, RDF.type, MAGC.Affiliation))\n",
    "                    g.add((c, ORG.memberOf, a)) ##  Author --> Affiliation \n",
    "            else:\n",
    "                c = search_author[0][0]\n",
    "            g.add((paper_node, DCTERMS.created, c))\n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183beb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOnePaper(g, row):\n",
    "    \n",
    "    articleInfo = row['data']['article']\n",
    "    if articleInfo['doi'] != None: \n",
    "        paper_node = URIRef(DOI_prefix+articleInfo['doi'])\n",
    "    else:\n",
    "        paper_node = BNode()\n",
    "    g.add((paper_node, RDF.type, MAGC.Paper))\n",
    "    \n",
    "    ## add meta info \n",
    "    if articleInfo['id']:\n",
    "        g.add((paper_node, DCTERMS.identifier, Literal(articleInfo['id'], datatype=XSD.string)))\n",
    "    if articleInfo['normalizedAbstract']:\n",
    "        g.add((paper_node, DCTERMS.abstract, Literal(articleInfo['normalizedAbstract'], datatype=XSD.string)))\n",
    "    if articleInfo['normalizedTitle']:\n",
    "        g.add((paper_node, DCTERMS.title, Literal(articleInfo['normalizedTitle'], datatype=XSD.string)))\n",
    "    if articleInfo['pubDate']: \n",
    "        g.add((paper_node, PRISM.publicationDate, Literal(articleInfo['pubDate'], datatype=XSD.date)))\n",
    "    if articleInfo['idPrefix']:\n",
    "        g.add((paper_node, PRISM.issueIdentifier, Literal(articleInfo['idPrefix'], datatype=XSD.string)))\n",
    "  \n",
    "    \n",
    "    ## add author:\n",
    "    g = addAuthorEntity(g, paper_node, row)\n",
    "    \n",
    "    ## \n",
    "    try:\n",
    "        g = addSemantics(g, row, paper_node)\n",
    "    except:\n",
    "        print('ERROR: add Semantics',row['llm'])\n",
    "#         sys.exit(\"Error message\")\n",
    "    \n",
    "#     g = addKeywords(g, row, paper_node)\n",
    "    \n",
    "    ## and journal \n",
    "    \n",
    "#     if 'issue' in row['data']:\n",
    "#         g = addIssueEntity(g, paper_node, row)\n",
    "#     else:\n",
    "#         g = addProceedEntity(g, paper_node, row)\n",
    "        \n",
    "    return g\n",
    "\n",
    "def addKeywords(g, row, paper_node):\n",
    "    keywords =  row['data']['article']['keywords']\n",
    "    for k in keywords:\n",
    "        mapped = mapKeyword2DB(k) \n",
    "        search_concept = searchKG(g, k, \"<http://tvcg.org/class/keyword>\")\n",
    "        if len(search_concept)==0:\n",
    "            c = BNode()\n",
    "            g.add((c, FOAF.name, Literal(k, datatype=XSD.string)))\n",
    "            g.add((c, RDF.type, TVCG_C.keyword))\n",
    "            if mapped!=None:\n",
    "                for d in mapped:\n",
    "                    g.add((c, TVCG_P.seeAlso, URIRef(\"https://dbpedia.org/page/\"+d)))\n",
    "                    g.add((URIRef(\"https://dbpedia.org/page/\"+d), FOAF.name, Literal(d, datatype=XSD.string)))\n",
    "                    g.add((URIRef(\"https://dbpedia.org/page/\"+d), RDF.type, URIRef(\"https://tvcg.org/class/DBPedia\")))\n",
    "        else:\n",
    "            c = search_concept[0][0]\n",
    "\n",
    "        g.add((paper_node, PRISM.keyword, c))\n",
    "\n",
    "    return g\n",
    "def searchKG(g, keyword, RDF_type_string):\n",
    "    sparql_ = f\"\"\"\n",
    "        SELECT *\n",
    "        where {{\n",
    "            ?target rdf:type  {RDF_type_string} .\n",
    "            ?target foaf:name \"{keyword}\"^^xsd:string .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = g.query(sparql_)\n",
    "        return list(output)\n",
    "    except:\n",
    "        print('ERROR: search Keyword',keyword)\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab91ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "ERROR: add Semantics {}\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "ERROR: add Semantics {}\n",
      "900\n",
      "1000\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "1100\n",
      "1200\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "1300\n",
      "ERROR: add Semantics {}\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "ERROR: add Semantics {}\n",
      "1900\n",
      "2000\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "ERROR: add Semantics {}\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "ERROR: add Semantics {}\n",
      "2700\n",
      "2800\n",
      "ERROR: add Semantics {}\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "ERROR: add Semantics {}\n",
      "3600\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "3700\n",
      "ERROR: add Semantics {}\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "ERROR: add Semantics {}\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "ERROR: add Semantics {}\n",
      "4800\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "ERROR: add Semantics {}\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "data = utils.loadjson('../kg_data/2_merged_data_llm.json')\n",
    "from rdflib import Graph\n",
    "g = Graph()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    ele = data[i]\n",
    "    g = processOnePaper(g, ele)\n",
    "    \n",
    "# g.serialize(destination = \"../kg_data/3_kg_v3.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e2d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nd688d79bf4bb4ad28621010878b75918 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination = \"../kg_data/kg_v6.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "90c6154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper_idx = [ele['data']['article']['id'] for ele in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c1be5ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    recommendations = data[i]['data']['recommendedArticles']\n",
    "    \n",
    "    current_node = searchPaper(g, data[i]['data']['article']['id'])\n",
    "    for r in recommendations:\n",
    "        idx = r['abstractUrl'].split('/')[-1]\n",
    "        if idx in all_paper_idx:\n",
    "            target_node = searchPaper(g, idx)\n",
    "            \n",
    "            g.add((current_node, TVCG_P.recommendedTo, target_node))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8847a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1ca7c07abd4d4fdd9d2edca3ef244992 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination = \"../kg_data/kg_v3.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "951f3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchPaper(g, idx):\n",
    "    sparql_ = f\"\"\"\n",
    "        SELECT *\n",
    "        where {{\n",
    "            ?target rdf:type <https://makg.org/class/Paper>;\n",
    "            <http://purl.org/dc/terms/identifier> '{idx}'^^xsd:string.\n",
    "        }}\n",
    "    \"\"\"\n",
    "    output = g.query(sparql_)\n",
    "    return list(output)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a13a55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchPaper(g, '1haUx0fpghW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af3fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[100]['data']['recommendedArticles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvis2024",
   "language": "python",
   "name": "pvis2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
